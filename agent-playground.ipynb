{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook introduces the utilization of LangChain and LLama 2 to assist us in finding recipes from the internet and subsequently consolidating the ingredients into a shopping list.\n",
    "\n",
    "The sequence of actions is as follows:\n",
    "\n",
    "1. User: Requests the bot to find a recipe for XYZ.\n",
    "2. Bot: Searches recipe sites based on user keywords and presents a list of options.\n",
    "3. User: Chooses one of the recipes and asks the bot to provide a list of ingredients.\n",
    "4. Bot: Presents the list of ingredients.\n",
    "(optional) \n",
    "5. User: Repeats step 1 to discover more recipes.\n",
    "6. User: Asks the bot to consolidate the ingredients.\n",
    "7. Bot: Presents the consolidated ingredient shopping list.\n",
    "\n",
    "\n",
    "*NOTE: This notebook employs the 13B model within LLama 2. Feel free to substitute the LLM with your preferred model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jeremylee/APIs/llama.cpp/models/13B/ggml-model-q4_0.bin'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# retrieving model path\n",
    "MODEL_PATH  = os.getenv('13B')\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/jeremylee/APIs/llama.cpp/models/13B/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 7024.01 MB (+ 3200.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  351.35 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "llama.cpp: loading model from /Users/jeremylee/APIs/llama.cpp/models/13B/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 7024.01 MB (+ 3200.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  351.35 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# llm\n",
    "\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=4096,\n",
    "    max_tokens=1024,\n",
    "    temperature=0.0, # to ensure consistant output, set to zero\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=DEBUG,\n",
    ")\n",
    "\n",
    "\n",
    "agent_callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "agent_llm = LlamaCpp(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=4096,\n",
    "    max_tokens=1024,\n",
    "    temperature=0.0, # to ensure consistant output, set to zero\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=agent_callback_manager,\n",
    "    verbose=DEBUG,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMChains\n",
    "For our task, we will employ three distinct LangChains:\n",
    "\n",
    "1. GetRecipeUrlChain: This chain is tasked with discovering recipe URLs based on user input.\n",
    "2. GetIngredientsFromContentChain: This chain is responsible for reading and extracting ingredients from the provided URL.\n",
    "3. ConsolidateIngredientsChain: This chain handles the aggregation of all the ingredients searched by the user into a comprehensive shopping list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GetRecipeUrlChain\n",
    "This chain uses a custom prompt template that find out the keyword of a recipe, call a `find_recipe` method, and then inject the result back to the prompt before asking llm to generate the output\n",
    "\n",
    "*Note: the `find_recipe` method can also be use as one of the agent's tool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspired by https://jonathansoma.com/words/three-ways-to-scrape-langchain.html\n",
    "### This function can be used as part of agent's tool.\n",
    "### See https://python.langchain.com/docs/modules/agents/tools/custom_tools\n",
    "\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "\n",
    "@tool(\"find_recipe\", return_direct=True, args_schema=SearchInput)\n",
    "def find_recipe(query: str) -> str:\n",
    "    \"\"\"Based on search input, return a list of recipes\"\"\"\n",
    "\n",
    "    url = f\"https://rasamalaysia.com/?s={query}\"\n",
    "\n",
    "    # Make the request\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0' }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Extract the link\n",
    "    soup = BeautifulSoup(response.text)\n",
    "\n",
    "    # Get all the URLS\n",
    "    links = soup.select(\"[class='entry-title-link']\")\n",
    "\n",
    "    return str(links).replace(\"\\n\", \"\")\n",
    "\n",
    "# Uncomment to test\n",
    "# recipe_query = \"rendang\"\n",
    "# find_recipe(recipe_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms.base import BaseLLM\n",
    "\n",
    "class SearchRecipeTemplate(StringPromptTemplate):\n",
    "    # this template gets user inputs, which is the keyword and then call \n",
    "    # external function, which in turn put it back to the template.\n",
    "    # the prompt input expects keyword\n",
    "\n",
    "    # the template to use\n",
    "    template: str\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        keyword = kwargs.pop(\"keyword\")\n",
    "        \n",
    "        text = find_recipe(keyword)\n",
    "        kwargs[\"text\"] = text\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "class GetRecipeURLChain(LLMChain):\n",
    "    \"\"\"Chain can extracts any URL from a given string\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Input any text with url, returns url\"\"\"\n",
    "\n",
    "        search_template = (\"Based on the following text\"\n",
    "                            \" extract their links and names: {text}\"\n",
    "                            \" Return first 3 results, like:\"\n",
    "                            \" name, url,\"\n",
    "                            \" name, url,\"\n",
    "                            \" name, url.\"\n",
    "                            )\n",
    "        prompt = SearchRecipeTemplate(\n",
    "            template=search_template, \n",
    "            input_variables=[\"keyword\"] # note, text will be placed by the SearchRecipeTemplate\n",
    "        )\n",
    "\n",
    "        return cls(prompt=prompt, llm=llm, verbose=DEBUG)\n",
    "\n",
    "get_recipe_url_chain = GetRecipeURLChain.from_llm(llm)\n",
    "\n",
    "# Uncomment to test\n",
    "# url = get_recipe_url_chain.run(keyword=\"rendang\")\n",
    "# url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GetIngredientsFromContentChain\n",
    "This chain also uses a custom prompt template to access a website by calling `web_content_extractor` method, and then extract the ingredient list and insert the result back to the prompt before asking llm to generate the output\n",
    "\n",
    "*Note: the `web_content_extractor` method can also be use as one of the agent's tool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to help extract content based on URL.\n",
    "# NOTE: This can be part of Agent's tool or be called directly.\n",
    "# In our case, we will call it directly from LLMChain instead\n",
    "\n",
    "class URLInput(BaseModel):\n",
    "    url: str = Field(description=\"must be be a URL\")\n",
    "\n",
    "\n",
    "@tool(\"get_url_content\", return_direct=True, args_schema=URLInput)\n",
    "def web_content_extractor(url: str) -> str:\n",
    "    \"\"\"Based on the given input URL, load and return the web content\"\"\"\n",
    "\n",
    "    if(url[:4] != \"http\"):\n",
    "        return \"URL must start with http. Please try again\"\n",
    "\n",
    "    # Make the request\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0' }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Extract the link\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Get all the URLS\n",
    "    ingredients = soup.find_all(\"div\",{\"class\":\"wprm-recipe-ingredient-group\"})\n",
    "    ingredient_list = [ingredient_div.get_text() for ingredient_div in ingredients]\n",
    "\n",
    "    return str(ingredient_list)\n",
    "\n",
    "# Uncomment to test\n",
    "# web_content_extractor(\"https://rasamalaysia.com/baked-cod/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "class GetRecipeFromUrlTemplate(StringPromptTemplate):\n",
    "    # this template gets user inputs, which is the keyword and then call \n",
    "    # external function, which in turn put it back to the template.\n",
    "    # the prompt input expects keyword\n",
    "\n",
    "    # the template to use\n",
    "    template: str\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        url = kwargs.pop(\"url\")\n",
    "\n",
    "        url_extract_pattern = \"https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n",
    "        formated_url = re.findall(url_extract_pattern, url)\n",
    "        \n",
    "        web_content = web_content_extractor(formated_url[0])\n",
    "        print(web_content)\n",
    "        kwargs[\"web_content\"] = web_content\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "class GetIngredientsFromContentChain(LLMChain):\n",
    "    \"\"\"Chain can extracts any URL from a given string\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Input content of webpage, output ingredient names and quantity and unit\"\"\"\n",
    "\n",
    "        ingredient_extraction_template = (\n",
    "                                          \" You will list all the ingredients\"\n",
    "                                          \" and their quantities based on this text: '{web_content}'\"\n",
    "                                          \" Add ### line before listing the ingredients.\"\n",
    "                                          \" Add === line after listing all the ingredients.\"\n",
    "                                          \" List down the ingredients, like:\"\n",
    "                                          \" ingredient A - X unit of measurement,\"\n",
    "                                          \" ingredient B - Y unit of measurement,\"\n",
    "                                          \" ingredient C - Z unit of measurement.\"\n",
    "                                          )\n",
    "\n",
    "        prompt = GetRecipeFromUrlTemplate(\n",
    "            template=ingredient_extraction_template, \n",
    "            input_variables=[\"url\"] # note, web_content will be replaced by GetRecipeFromUrlTemplate, which in turn replaces web_content\n",
    "        )\n",
    "\n",
    "        return cls(prompt=prompt, llm=llm, verbose=DEBUG)\n",
    "\n",
    "get_ingredients_from_content_chain = GetIngredientsFromContentChain.from_llm(llm)\n",
    "\n",
    "# Uncomment to test\n",
    "# ingredients = get_ingredients_from_content_chain.run(url=\" the url is https://rasamalaysia.com/beef-rendang-recipe-rendang-daging/>\")\n",
    "# ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConsolidateIngredientsChain\n",
    "Similar to the previous chain, this also uses custom prompt template.\n",
    "\n",
    "*NOTE: We are supposed to use a database to store all the searched ingredients. However, I am using an array for convenience instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with a database for permanent storage instead\n",
    "ingredients = []\n",
    "\n",
    "@tool\n",
    "def save_ingredients(ingredient: str):\n",
    "    \"\"\"save ingredients to memory\"\"\"\n",
    "    ingredients.append(ingredient)\n",
    "\n",
    "@tool\n",
    "def get_ingredients(input: str) -> str:\n",
    "    \"\"\"get ingredients from memory\"\"\"\n",
    "    ingredient_string = \"\"\n",
    "    for i in ingredients:\n",
    "        ingredient_string = ingredient_string + \" \" + i.replace(\"Ingredients:\", \"\") \n",
    "    return ingredient_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetIngredientsFromDBTemplate(StringPromptTemplate):\n",
    "\n",
    "    # the template to use\n",
    "    template: str\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "\n",
    "        ingredients = get_ingredients('')\n",
    "\n",
    "        kwargs[\"ingredients\"] = ingredients\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "class ConsolidateIngredientsChain(LLMChain):\n",
    "    \"\"\"Chain to consolidate ingredients\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        \"\"\"Input a list of ingredients, output ingredient names and quantity and unit\"\"\"\n",
    "        \n",
    "        consolidate_ingredients_template = (\"Are an expert in identifying and consolidating ingredients\"\n",
    "                                        \" from this content: '{ingredients}'.\"\n",
    "                                        \" If there are similar ingredients, sum up their quantity.\"\n",
    "                                        \" For other ingredients, just return their name and quantity.\"\n",
    "                                        \" Do not suggest other ingredients that are not in the text.\"\n",
    "                                        \" Please identify and consolidate the ingredients, like:\"\n",
    "                                        \" ingredient A (quantity),\"\n",
    "                                        \" ingredient B (quantity).\"\n",
    "                                        )\n",
    "        prompt = GetIngredientsFromDBTemplate(\n",
    "            template=consolidate_ingredients_template,\n",
    "            input_variables=['text']\n",
    "        )\n",
    "\n",
    "        return cls(prompt=prompt, llm=llm, verbose=DEBUG)\n",
    "\n",
    "consolidate_ingredients_chain = ConsolidateIngredientsChain.from_llm(llm)\n",
    "\n",
    "\n",
    "# Uncomment to test\n",
    "# ingredients = [\"\"\"Ingredients:\n",
    "# * 1 tablespoon oil\n",
    "# * 1 1/2 tablespoons red curry paste (Mae Ploy)\n",
    "# * 4 oz. big scallops\n",
    "# * 4 oz. boneless and skinless chicken breast (cut into small cubes)\n",
    "# * 80 ml. coconut milk\n",
    "# * 1/4 cup water\n",
    "# * 2 long beans (cut into 2-inch lengths)\n",
    "# * 1/2 cup thickly sliced carrot\n",
    "# * 1 kaffir lime leave (cut into fine thin strips, optional)\n",
    "# * 1/4 teaspoon fish sauce\n",
    "# * 2 teaspoons palm sugar or sugar\"\"\"\n",
    "# ]\n",
    "\n",
    "# print(get_ingredients(\"\"))\n",
    "# output = consolidate_ingredients_chain.run(text='')\n",
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "We can then use an agent to help with our quest of finding and consolidating ingredients into a shopping list! \n",
    "\n",
    "Things to note:\n",
    "1. I use a `BaseCallbackkHandler` to save the ingredients that `get_ingredients_from_content_chain` returns\n",
    "2. The agent has 2 optional parameters to help handle edge case:\n",
    "* `handle_parsing_errors=True` enables the agent to think about the error and refine its answer\n",
    "* `max_iterations=5` ensures that the agent does not go into an infinite loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom memory. LLama 2 as llm agent is still not able to hold a REACT \n",
    "# conversation well beyond 2 turns with long tokens. Modify it's memory so that \n",
    "# long replies are reduced.\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from typing import Any, Dict\n",
    "\n",
    "class CustomConversationBufferMemory(ConversationBufferWindowMemory):\n",
    "\n",
    "    # overriding save_context method.\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save context from this conversation to buffer.\"\"\"\n",
    "        input_str, output_str = self._get_input_output(inputs, outputs)\n",
    "        \n",
    "        if(len(output_str.split(\" \")) > 40):\n",
    "            # self.chat_memory.add_ai_message(\"[long reply]\") \n",
    "            # don't save it\n",
    "            pass\n",
    "        else:\n",
    "            self.chat_memory.add_user_message(input_str)\n",
    "            self.chat_memory.add_ai_message(output_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "# refer to https://python.langchain.com/docs/modules/memory/agent_with_memory\n",
    "# for agent to gain memory\n",
    "\n",
    "class SaveIngredientsHandler(BaseCallbackHandler):\n",
    "    def on_tool_start(self, serialized, input_str: str, **kwargs):\n",
    "        \"\"\"Run when tool starts running.\"\"\"\n",
    "\n",
    "    def on_tool_end(self, output: str, **kwargs):\n",
    "        \"\"\"Run when tool ends running.\"\"\"\n",
    "\n",
    "        ingredient = output.split(\"###\")\n",
    "        if len(ingredient) == 1:\n",
    "            save_ingredients(output)\n",
    "        else:\n",
    "            just_ingredient = ingredient[1].split(\"===\")\n",
    "            save_ingredients(just_ingredient[0])\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"get_recipe_by_keyword\",\n",
    "        func=get_recipe_url_chain.run,\n",
    "        description=\"\"\"useful for finding recipes based \\\n",
    "            on user keywords\"\"\",\n",
    "        return_direct = True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_ingredients_by_url\",\n",
    "        func=get_ingredients_from_content_chain.run,\n",
    "        description=\"\"\"useful for extracting out ingredients \\\n",
    "            from the recipe url. \\\n",
    "            Save the ingredients after that\"\"\",\n",
    "        callbacks=[SaveIngredientsHandler()],\n",
    "        return_direct = True\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"summarise_ingredients\",\n",
    "        func=consolidate_ingredients_chain.run,\n",
    "        description=\"\"\"useful when you want to summarise \\\n",
    "            all the ingredients after getting them from memory. \\\n",
    "            Do not use this to consolidate recipes.\"\"\",\n",
    "        return_direct = True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "prefix = \"\"\"You are a shopping assistant who is an expert at\n",
    "    finding food ingredients based on user inputs.\n",
    "    If there are multiple recipes, ask user to select one before proceeding. \n",
    "    Then extract out the ingredients of the selected recipe.\n",
    "    Finally, consolidate the ingredients when user is done.\n",
    "    If you are unsure of the next step, show your output and ask user for input.\n",
    "    Do not role play in the conversation. For example, generating AI and Human \n",
    "    conversation is not allowed.\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "agent_prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "\n",
    "# memory = CustomConversationBufferMemory(memory_key=\"chat_history\")\n",
    "memory = CustomConversationBufferMemory(k=1, memory_key=\"chat_history\")\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=agent_llm, prompt=agent_prompt)\n",
    "\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=DEBUG)\n",
    "\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=DEBUG, memory=memory,\n",
    "    # handle_parsing_errors=\"Check your output and make sure it conforms!\"\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference!\n",
    "Let's test our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "Thought: Hmm, that's a good question. Let me think...\n",
      "\n",
      "Action: get_recipe_by_keyword\n",
      "Action Input: \"curry\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 10879.74 ms\n",
      "llama_print_timings:      sample time =    29.57 ms /    43 runs   (    0.69 ms per token,  1453.93 tokens per second)\n",
      "llama_print_timings: prompt eval time = 10879.70 ms /   365 tokens (   29.81 ms per token,    33.55 tokens per second)\n",
      "llama_print_timings:        eval time =  4192.93 ms /    42 runs   (   99.83 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time = 15167.05 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Hmm, that's a good question. Let me think...\n",
      "\n",
      "Action: get_recipe_by_keyword\n",
      "Action Input: \"curry\"\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GetRecipeURLChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBased on the following text extract their links and names: [<a class=\"entry-title-link\" href=\"https://rasamalaysia.com/green-curry/\" rel=\"bookmark\">Green Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/red-curry-recipe/\" rel=\"bookmark\">Thai Red Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/curry-meecurry-laksa-recipe/\" rel=\"bookmark\">Curry Laksa (Curry Mee)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/thai-yellow-curry/\" rel=\"bookmark\">Yellow Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/thai-recipe-chicken-panang-curry/\" rel=\"bookmark\">Panang Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/green-curry-shrimp/\" rel=\"bookmark\">Green Curry Shrimp</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/beef-massaman-curry-recipe/\" rel=\"bookmark\">Massaman Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/chicken-curry-with-potatoes/\" rel=\"bookmark\">Chicken Curry with Potatoes</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/red-chicken-curry/\" rel=\"bookmark\">Red Chicken Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/penang-curry-mee-recipe/\" rel=\"bookmark\">Penang Curry Mee</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/thai-curry/\" rel=\"bookmark\">Thai Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/chicken-curry-recipe/\" rel=\"bookmark\">Chicken Curry</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/honey-garlic-salmon/\">\t\tHoney Garlic Salmon\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/baked-cod/\">\t\tBaked Cod\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/chicken-tenders/\">\t\tGarlic Butter Chicken Tenders\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/honey-garlic-pork-chops/\">\t\tBoneless Pork Chops\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/slow-cooker-honey-sesame-chicken-wings/\">\t\tSlow Cooker Honey Sesame Chicken Wings\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-honey-sesame-pulled-pork/\">\t\tCrock Pot Honey Sesame Pulled Pork\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-asian-beef-stew-2/\">\t\tCrock Pot Asian Beef Stew\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-honey-teriyaki-chicken/\">\t\tSlow Cooker Honey Teriyaki Chicken\t\t\t</a>] Return first 3 results, like: name, url, name, url, name, url.\u001b[0m\n",
      "\n",
      "\n",
      "The first three results are:\n",
      "\n",
      "1. Green Curry <https://rasamalaysia.com/green-curry/>\n",
      "2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\n",
      "3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The first three results are:\n",
      "\n",
      "1. Green Curry <https://rasamalaysia.com/green-curry/>\n",
      "2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\n",
      "3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 16133.29 ms\n",
      "llama_print_timings:      sample time =    64.33 ms /    93 runs   (    0.69 ms per token,  1445.72 tokens per second)\n",
      "llama_print_timings: prompt eval time = 38697.47 ms /   991 tokens (   39.05 ms per token,    25.61 tokens per second)\n",
      "llama_print_timings:        eval time =  8232.25 ms /    92 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time = 47147.07 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe first three results are:\\n\\n1. Green Curry <https://rasamalaysia.com/green-curry/>\\n2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\\n3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What are the ingredients in curry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What are the ingredients in curry?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe first three results are:\\n\\n1. Green Curry <https://rasamalaysia.com/green-curry/>\\n2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\\n3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history', k=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I will extract the ingredients from the first recipe.\n",
      "Action: get_ingredients_by_url\n",
      "Action Input: https://rasamalaysia.com/green-curry/\u001b[32;1m\u001b[1;3mThought: I will extract the ingredients from the first recipe.\n",
      "Action: get_ingredients_by_url\n",
      "Action Input: https://rasamalaysia.com/green-curry/\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GetIngredientsFromContentChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 10879.74 ms\n",
      "llama_print_timings:      sample time =    35.60 ms /    52 runs   (    0.68 ms per token,  1460.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  6020.03 ms /   116 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =  4187.66 ms /    51 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time = 10321.96 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▢ 1 1/2 tablespoons oil▢ 2 tbsp green curry paste (Maesri brand preferred)▢ 8 oz. chicken breast, cut into bite-sized pieces▢ 1/2 cup coconut milk▢ 1/2 cup water▢ 4 oz. bamboo shoot▢ 5 kaffir lime leaves (lightly bruised)▢ 2 red chilies (cut into thick strips)▢ 1 tablespoon fish sauce▢ 1 tablespoon sugar or palm sugar (preferred)▢ 1/4 cup Thai basil leaves']\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You will list all the ingredients and their quantities based on this text: '['▢ 1 1/2 tablespoons oil▢ 2 tbsp green curry paste (Maesri brand preferred)▢ 8 oz. chicken breast, cut into bite-sized pieces▢ 1/2 cup coconut milk▢ 1/2 cup water▢ 4 oz. bamboo shoot▢ 5 kaffir lime leaves (lightly bruised)▢ 2 red chilies (cut into thick strips)▢ 1 tablespoon fish sauce▢ 1 tablespoon sugar or palm sugar (preferred)▢ 1/4 cup Thai basil leaves']' Add ### line before listing the ingredients. Add === line after listing all the ingredients. List down the ingredients, like: ingredient A - X unit of measurement, ingredient B - Y unit of measurement, ingredient C - Z unit of measurement.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Ingredients:\n",
      "\n",
      "* 1 1/2 tablespoons oil\n",
      "* 2 tbsp green curry paste (Maesri brand preferred)\n",
      "* 8 oz. chicken breast, cut into bite-sized pieces\n",
      "* 1/2 cup coconut milk\n",
      "* 1/2 cup water\n",
      "* 4 oz. bamboo shoot\n",
      "* 5 kaffir lime leaves (lightly bruised)\n",
      "* 2 red chilies (cut into thick strips)\n",
      "* 1 tablespoon fish sauce\n",
      "* 1 tablespoon sugar or palm sugar (preferred)\n",
      "* 1/4 cup Thai basil leaves\n",
      "\n",
      "===\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "### Ingredients:\n",
      "\n",
      "* 1 1/2 tablespoons oil\n",
      "* 2 tbsp green curry paste (Maesri brand preferred)\n",
      "* 8 oz. chicken breast, cut into bite-sized pieces\n",
      "* 1/2 cup coconut milk\n",
      "* 1/2 cup water\n",
      "* 4 oz. bamboo shoot\n",
      "* 5 kaffir lime leaves (lightly bruised)\n",
      "* 2 red chilies (cut into thick strips)\n",
      "* 1 tablespoon fish sauce\n",
      "* 1 tablespoon sugar or palm sugar (preferred)\n",
      "* 1/4 cup Thai basil leaves\n",
      "\n",
      "===\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 16133.29 ms\n",
      "llama_print_timings:      sample time =   111.21 ms /   162 runs   (    0.69 ms per token,  1456.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  7058.44 ms /   241 tokens (   29.29 ms per token,    34.14 tokens per second)\n",
      "llama_print_timings:        eval time = 12362.43 ms /   161 runs   (   76.79 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time = 19780.10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n### Ingredients:\\n\\n* 1 1/2 tablespoons oil\\n* 2 tbsp green curry paste (Maesri brand preferred)\\n* 8 oz. chicken breast, cut into bite-sized pieces\\n* 1/2 cup coconut milk\\n* 1/2 cup water\\n* 4 oz. bamboo shoot\\n* 5 kaffir lime leaves (lightly bruised)\\n* 2 red chilies (cut into thick strips)\\n* 1 tablespoon fish sauce\\n* 1 tablespoon sugar or palm sugar (preferred)\\n* 1/4 cup Thai basil leaves\\n\\n==='"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"first option!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What are the ingredients in curry?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe first three results are:\\n\\n1. Green Curry <https://rasamalaysia.com/green-curry/>\\n2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\\n3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history', k=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should ask the user which recipe they want to use.\n",
      "Action: get_recipe_by_keyword\n",
      "Action Input: Nasi Lemak"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 10879.74 ms\n",
      "llama_print_timings:      sample time =    28.01 ms /    40 runs   (    0.70 ms per token,  1427.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   760.98 ms /    12 tokens (   63.41 ms per token,    15.77 tokens per second)\n",
      "llama_print_timings:        eval time =  3154.09 ms /    39 runs   (   80.87 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =  4002.26 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I should ask the user which recipe they want to use.\n",
      "Action: get_recipe_by_keyword\n",
      "Action Input: Nasi Lemak\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GetRecipeURLChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBased on the following text extract their links and names: [<a class=\"entry-title-link\" href=\"https://rasamalaysia.com/nasi-lemak-recipe/\" rel=\"bookmark\">Nasi Lemak</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/\" rel=\"bookmark\">Nasi Goreng (Indonesian Fried Rice)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/nasi-ulam-recipe/\" rel=\"bookmark\">Nasi Ulam (Malaysian Mixed Herb Rice)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/udang-masak-lemak-nenas-pineapple-prawn-curry/\" rel=\"bookmark\">Pineapple Prawn Curry (Udang Masak Lemak Nenas)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/beef-rendang-recipe-rendang-daging/\" rel=\"bookmark\">Beef Rendang</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/recipe-assam-pedas-fish/\" rel=\"bookmark\">Asam Pedas Fish</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/rasa-malaysia-recipe-index/\" rel=\"bookmark\">Rasa Malaysia Recipe Index</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/mie-goreng-indonesian-fried-noodles/\" rel=\"bookmark\">Indonesian Fried Noodles (Mie Goreng)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/walnut-cookies/\" rel=\"bookmark\">Walnut Cookies</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/parmesan-chiffon-cake/\" rel=\"bookmark\">Parmesan Chiffon Cake</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/best-ever-pineapple-cookies-pineapple-tarts/\" rel=\"bookmark\">Best-Ever Pineapple Cookies (Pineapple Tarts)</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/walnut-butter-cake/\" rel=\"bookmark\">Walnut Butter Cake</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/honey-garlic-salmon/\">\t\tHoney Garlic Salmon\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/baked-cod/\">\t\tBaked Cod\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/chicken-tenders/\">\t\tGarlic Butter Chicken Tenders\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/honey-garlic-pork-chops/\">\t\tBoneless Pork Chops\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/slow-cooker-honey-sesame-chicken-wings/\">\t\tSlow Cooker Honey Sesame Chicken Wings\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-honey-sesame-pulled-pork/\">\t\tCrock Pot Honey Sesame Pulled Pork\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-asian-beef-stew-2/\">\t\tCrock Pot Asian Beef Stew\t\t\t</a>, <a class=\"entry-title-link\" href=\"https://rasamalaysia.com/crock-pot-honey-teriyaki-chicken/\">\t\tSlow Cooker Honey Teriyaki Chicken\t\t\t</a>] Return first 3 results, like: name, url, name, url, name, url.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The links and names of the first three results are:\n",
      "\n",
      "1. Nasi Lemak - <https://rasamalaysia.com/nasi-lemak-recipe/>\n",
      "2. Nasi Goreng (Indonesian Fried Rice) - <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\n",
      "3. Nasi Ulam (Malaysian Mixed Herb Rice) - <https://rasamalaysia.com/nasi-ulam-recipe/>\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The links and names of the first three results are:\n",
      "\n",
      "1. Nasi Lemak - <https://rasamalaysia.com/nasi-lemak-recipe/>\n",
      "2. Nasi Goreng (Indonesian Fried Rice) - <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\n",
      "3. Nasi Ulam (Malaysian Mixed Herb Rice) - <https://rasamalaysia.com/nasi-ulam-recipe/>\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 16133.29 ms\n",
      "llama_print_timings:      sample time =    84.53 ms /   123 runs   (    0.69 ms per token,  1455.19 tokens per second)\n",
      "llama_print_timings: prompt eval time = 38632.95 ms /  1074 tokens (   35.97 ms per token,    27.80 tokens per second)\n",
      "llama_print_timings:        eval time = 10907.25 ms /   122 runs   (   89.40 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time = 49822.38 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe links and names of the first three results are:\\n\\n1. Nasi Lemak - <https://rasamalaysia.com/nasi-lemak-recipe/>\\n2. Nasi Goreng (Indonesian Fried Rice) - <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\\n3. Nasi Ulam (Malaysian Mixed Herb Rice) - <https://rasamalaysia.com/nasi-ulam-recipe/>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What is the recipe for Nasi Lemak?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What are the ingredients in curry?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe first three results are:\\n\\n1. Green Curry <https://rasamalaysia.com/green-curry/>\\n2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\\n3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>', additional_kwargs={}, example=False), HumanMessage(content='What is the recipe for Nasi Lemak?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe links and names of the first three results are:\\n\\n1. Nasi Lemak - <https://rasamalaysia.com/nasi-lemak-recipe/>\\n2. Nasi Goreng (Indonesian Fried Rice) - <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\\n3. Nasi Ulam (Malaysian Mixed Herb Rice) - <https://rasamalaysia.com/nasi-ulam-recipe/>', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history', k=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should extract the ingredients from the second recipe\n",
      "Action: get_ingredients_by_url\n",
      "Action Input: <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\u001b[32;1m\u001b[1;3mThought: I should extract the ingredients from the second recipe\n",
      "Action: get_ingredients_by_url\n",
      "Action Input: <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GetIngredientsFromContentChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 10879.74 ms\n",
      "llama_print_timings:      sample time =    42.10 ms /    61 runs   (    0.69 ms per token,  1449.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  6066.07 ms /   142 tokens (   42.72 ms per token,    23.41 tokens per second)\n",
      "llama_print_timings:        eval time =  4938.55 ms /    60 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time = 11141.33 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▢ 1 clove shallot▢ 1 clove garlic▢ 1 red chili (seeded)▢ 1/2 teaspoon toasted belacan (terasi)▢ 1/2 teaspoon palm sugar▢ 1/2 tablespoon kecap manis▢ 8 oz. overnight rice▢ 1 fried egg (well done)▢ 2 tablespoons oil']\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You will list all the ingredients and their quantities based on this text: '['▢ 1 clove shallot▢ 1 clove garlic▢ 1 red chili (seeded)▢ 1/2 teaspoon toasted belacan (terasi)▢ 1/2 teaspoon palm sugar▢ 1/2 tablespoon kecap manis▢ 8 oz. overnight rice▢ 1 fried egg (well done)▢ 2 tablespoons oil']' Add ### line before listing the ingredients. Add === line after listing all the ingredients. List down the ingredients, like: ingredient A - X unit of measurement, ingredient B - Y unit of measurement, ingredient C - Z unit of measurement.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here is the list of ingredients based on the text you provided:\n",
      "\n",
      "### Ingredients:\n",
      "\n",
      "* 1 clove shallot - 1\n",
      "* 1 clove garlic - 1\n",
      "* 1 red chili (seeded) - 1\n",
      "* 1/2 teaspoon toasted belacan (terasi) - 1/2\n",
      "* 1/2 teaspoon palm sugar - 1/2\n",
      "* 1/2 tablespoon kecap manis - 1/2\n",
      "* 8 oz. overnight rice - 8 oz\n",
      "* 1 fried egg (well done) - 1\n",
      "* 2 tablespoons oil - 2\n",
      "\n",
      "=== Total ingredients: 7\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Here is the list of ingredients based on the text you provided:\n",
      "\n",
      "### Ingredients:\n",
      "\n",
      "* 1 clove shallot - 1\n",
      "* 1 clove garlic - 1\n",
      "* 1 red chili (seeded) - 1\n",
      "* 1/2 teaspoon toasted belacan (terasi) - 1/2\n",
      "* 1/2 teaspoon palm sugar - 1/2\n",
      "* 1/2 tablespoon kecap manis - 1/2\n",
      "* 8 oz. overnight rice - 8 oz\n",
      "* 1 fried egg (well done) - 1\n",
      "* 2 tablespoons oil - 2\n",
      "\n",
      "=== Total ingredients: 7\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 16133.29 ms\n",
      "llama_print_timings:      sample time =   120.12 ms /   174 runs   (    0.69 ms per token,  1448.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5848.09 ms /   192 tokens (   30.46 ms per token,    32.83 tokens per second)\n",
      "llama_print_timings:        eval time = 13323.64 ms /   173 runs   (   77.02 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time = 19567.87 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nHere is the list of ingredients based on the text you provided:\\n\\n### Ingredients:\\n\\n* 1 clove shallot - 1\\n* 1 clove garlic - 1\\n* 1 red chili (seeded) - 1\\n* 1/2 teaspoon toasted belacan (terasi) - 1/2\\n* 1/2 teaspoon palm sugar - 1/2\\n* 1/2 tablespoon kecap manis - 1/2\\n* 8 oz. overnight rice - 8 oz\\n* 1 fried egg (well done) - 1\\n* 2 tablespoons oil - 2\\n\\n=== Total ingredients: 7'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"second option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What are the ingredients in curry?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe first three results are:\\n\\n1. Green Curry <https://rasamalaysia.com/green-curry/>\\n2. Thai Red Curry <https://rasamalaysia.com/red-curry-recipe/>\\n3. Curry Laksa (Curry Mee) <https://rasamalaysia.com/curry-laksa-recipe/>', additional_kwargs={}, example=False), HumanMessage(content='What is the recipe for Nasi Lemak?', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe links and names of the first three results are:\\n\\n1. Nasi Lemak - <https://rasamalaysia.com/nasi-lemak-recipe/>\\n2. Nasi Goreng (Indonesian Fried Rice) - <https://rasamalaysia.com/nasi-goreng-indonesian-fried-rice/>\\n3. Nasi Ulam (Malaysian Mixed Herb Rice) - <https://rasamalaysia.com/nasi-ulam-recipe/>', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history', k=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Ingredients:\\n\\n* 1 1/2 tablespoons oil\\n* 2 tbsp green curry paste (Maesri brand preferred)\\n* 8 oz. chicken breast, cut into bite-sized pieces\\n* 1/2 cup coconut milk\\n* 1/2 cup water\\n* 4 oz. bamboo shoot\\n* 5 kaffir lime leaves (lightly bruised)\\n* 2 red chilies (cut into thick strips)\\n* 1 tablespoon fish sauce\\n* 1 tablespoon sugar or palm sugar (preferred)\\n* 1/4 cup Thai basil leaves\\n\\n',\n",
       " ' Ingredients:\\n\\n* 1 clove shallot - 1\\n* 1 clove garlic - 1\\n* 1 red chili (seeded) - 1\\n* 1/2 teaspoon toasted belacan (terasi) - 1/2\\n* 1/2 teaspoon palm sugar - 1/2\\n* 1/2 tablespoon kecap manis - 1/2\\n* 8 oz. overnight rice - 8 oz\\n* 1 fried egg (well done) - 1\\n* 2 tablespoons oil - 2\\n\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lessons Learned\n",
    "\n",
    "Here are the lessons that I have learned from this notebook. As a caveat, I am using Llama 2, a 13B parameter chat model that is quantized. This means that a different LLM model might yield different results.\n",
    "\n",
    "## Llama 2 as an LLM\n",
    "- This proof-of-concept has taught me that the LLM requires multiple iterations of prompting to generate a somewhat satisfactory outcome.\n",
    "- It is also prone to generating random text even with minute changes to the prompt, such as an additional space.\n",
    "- The model also does not follow instructions very well; for example, it often failed to generate the output based on your provided prompt. The more robust 70B model might follow instructions better. However, it is not supported by llama.cpp at this point, and the text generation might be too slow even for the most powerful Apple silicon chip.\n",
    "- Similarly, when using the LLM as an agent, it tends to veer off a conversation after a few turns, highlighting the need for proper memory management.\n",
    "\n",
    "## Langchain to Supercharge LLM\n",
    "- Langchain is a promising framework to automate workflows, especially for instructions that are not well-structured.\n",
    "- Langchain's agent has the potential to be a game changer in completing tasks specified by humans and non-humans. However, the current limiting factor lies in the robustness of the LLM used, which I believe will improve over time.\n",
    "- One limiting aspect of the agent is that it might not always utilize the correct tool for a given task, as shown in this example. One approach to overcome this limitation is to create multiple agents that specialize in specific tasks and then control the workflow using more traditional engineering methods.\n",
    "\n",
    "## Moving Forward\n",
    "One of my hypotheses is that a more robust LLM will follow instructions more effectively, and this could be a potential follow-up task for this notebook.\n",
    "\n",
    "Furthermore, it's important to note that this notebook is focusing purely on Langchain implementation, which does not necessarily represent the real-world norms of software development. A more comprehensive end-to-end approach might reveal additional insights and could be a potential project for the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-4J6cmwWz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
